# ResponsibleAI-Airlift-Aug2020

## Overview

This repository contains content of a two-part workshop for using machine learning interpretability and fairness assessment (+ unfairness mitigation) to build fairer and more transparent models. The different components of the workshop are as follows:

Part 1: Interpretability with glassbox models (EBM)
Part 2: Explain blackbox models with SHAP (and upload explanations to Azure Machine Learning)
Part 3: Run Interpretability on Azure Machine Learning
Part 4: Model fairness assessment and unfairness mitigation

## Targeted audience
CSAs, DS


## Requirements/Prequsite 
**Individuals must bring/use their own subscription.**

If you do not have a subscription, you can create a free account by going to this link [free azure account](https://azure.microsoft.com/en-gb/free/search/?&OCID=AID2000125_SEM_Xvn0NgAAAQ0pAAG6:20200629090126:s&msclkid=9c0eb6425d2b1b0b16dee8bba9187880&ef_id=Xvn0NgAAAQ0pAAG6:20200629090126:s&dclid=CLygivWXp-oCFUruUQod3UIHtA)

### Environment Setup 



## Labs 

The labs are available on the following link [Labs](https://github.com/mufajjul/aml-govsec2020-workshop/tree/master/labs)

## Slides
The slides are available on the following link [Slides](https://github.com/mufajjul/aml-govsec2020-workshop/tree/master/slides)



##  Agenda:
-----------

----

# Feedback 

**Please provide feedback by visiting this link: [click here ](https://forms.office.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbRy65IxdWegNLmkUZoFUsoatUMko0SjZKSjFMNjFIUzQ0Q0RENTkzWlFDNS4u)**
